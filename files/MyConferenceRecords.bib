Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{ADiLauraJHenckelMBelzunceHHothi2020,
address = {The British Hip Society (BHS) Annual Scientific Meeting, Newport, Wales},
author = {{Di Laura}, A and Henckel, J and Belzunce, M and Hothi, H and Hart, A},
booktitle = {Orthop. Proc.},
title = {{The Uncertainty of Femoral Anteversion in Total Hip Arthroplasty}},
url = {https://online.boneandjoint.org.uk/doi/abs/10.1302/1358-992X.2020.5.024},
year = {2020}
}
@inproceedings{Belzunce2016,
abstract = {In 3D PET an axial compression is often applied to reduce the data size and the computation times during image reconstruction. This compression scheme can achieve good results in the centre of the FOV. However, there is a loss in the spatial resolution at off-centre positions and this effect is increased in scanners with a larger FOV. This is the case for the Siemens Biograph mMR, which by default uses an axial compression of span 11. An assessment of the improvement in the spatial resolution that would be achieved in a reconstruction without axial compression, is necessary to evaluate if the additional computational burden is justified for routine image reconstruction. In this work, we present an implementation of the ordinary Poisson ordered subsets expectation maximization (OP-OSEM) algorithm without axial compression for the mMR, and evaluate its performance for span 1 and span 11. We show that an improvement of 3 mm FWHM (i.e. an improvement of 40{\%}) can be achieved when span 11 compression is avoided and the source is at a distance greater than 100 mm from the centre of the FOV. In addition, the general image quality properties of the algorithm were evaluated with a NEMA image quality phantom acquisition and contrasted with its reconstruction via the STIR open source reconstruction software.},
author = {Belzunce, Martin A. and O'Doherty, Jim and Reader, Andrew J.},
booktitle = {2015 IEEE Nucl. Sci. Symp. Med. Imaging Conf. NSS/MIC 2015},
doi = {10.1109/NSSMIC.2015.7582054},
isbn = {9781467398626},
title = {{Impact of axial compression for the mMR simultaneous PET-MR scanner}},
year = {2016}
}
@inproceedings{Belzunce2017,
abstract = {High resolution and good quantification is needed in specific regions of the brain in a number of PET brain imaging applications. An improvement in the spatial resolution and in the quantification of the tracer uptake can be achieved by using statistical reconstruction methods with an accurate model of the scanner acquisition process. This model is represented by a system response matrix and needs to include all the factors that contribute to the degradation of the reconstructed images. Monte Carlo simulations are the best method to model the complex physical processes involved in PET, but they have an extremely high computational cost and the system matrix needs to be recomputed for every new scan. Furthermore, for 3D PET the system matrix can have billions of elements, therefore at present it is impossible to store in memory during the iterative reconstruction. Consequently, on-the-fly Monte Carlo modelling of the system matrix has been previously proposed by other authors, where a Monte Carlo simulation is used in the forward projector and a simpler analytic model in the backprojector. In this work, we propose a different approach, where a composite system matrix is used, with a complete Monte Carlo model computed with GATE for a small subregion of the field of view and a simpler analytic model for the voxels outside that region. We evaluated the feasibility of the method using 2D simulations of a striatum phantom and a brain phantom. For each case, a Monte Carlo system matrix was generated with GATE for a subregion centred in the striatum. The brain simulations were reconstructed using the proposed method and compared with the standard reconstruction used clinically, with and without resolution modelling. For the striatum phantom, the use of a GATE system matrix showed an improvement of the reconstructed image, where a better definition of the structures in the striatum region was observed. For the case of the brain phantom, where the composite system matrix is used, an improvement was also observed but more limited compared with the pure GATE system matrix.},
author = {Belzunce, Martin A. and Reader, Andrew J.},
booktitle = {2016 IEEE Nucl. Sci. Symp. Med. Imaging Conf. Room-Temperature Semicond. Detect. Work. NSS/MIC/RTSD 2016},
doi = {10.1109/NSSMIC.2016.8069558},
isbn = {9781509016426},
title = {{Composite system modelling for high accuracy brain PET image reconstruction using GATE}},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{Belzunce2016a,
abstract = {Normalization of the lines of response (LORs) or sinogram bins is necessary to avoid artifacts in fully 3D PET imaging. Component-based normalization (CBN) is an effective strategy to generate normalization factors (NFs) from short time scans of known emission sources. In the CBN, the NFs can be factorized into time-invariant and time-variant components. The effective crystal efficiencies are the main time-variant component, and a frequent normalization scan is needed to update their values. Therefore, it would be advantageous to be able to estimate unique effective crystal efficiencies to account for this time-variant component. In this work, we present a self-normalization algorithm to estimate the crystal efficiencies directly from any emission acquisition. The algorithm is based on the principle that if the true image were known, the mismatch between its projections, corrected for the time-invariant NFs, and the acquired data could be used to estimate the effective crystal efficiencies. We show that the algorithm successfully estimates the effective crystal efficiencies for simulated sinograms with different levels of Poisson noise and for different distributions of crystals efficiencies. This algorithm permits the reconstruction of good quality images without the need for an independent, separate, normalization scan. A key advantage of the method is the estimation of relatively few parameters (∼ 104) compared to the number of NFs for 3D data (∼ 108).},
author = {Belzunce, Martin A. and Reader, Andrew J.},
booktitle = {2015 IEEE Nucl. Sci. Symp. Med. Imaging Conf. NSS/MIC 2015},
doi = {10.1109/NSSMIC.2015.7582049},
isbn = {9781467398626},
title = {{Self-normalization of 3D PET data by estimating scan-dependent effective crystal efficiencies}},
year = {2016}
}
@inproceedings{Venialgo2011,
abstract = {This paper presents a calibration method for obtaining data to adjust nonlinear position estimation algorithms. This procedure is based on two measurements utilizing specialized collimators and a background subtraction algorithm. Since this method does not require electronic collimation, each PET detector module can be calibrated using a source of gamma-rays with a simple measurement setup. A nonlinear position estimation algorithm based in Artificial Neural Networks (ANNs) was evaluated. Its adjustment measurements were obtained utilizing this calibration method with a low cost PET detector module. The detector module consists of a continuous NaI(Tl) crystal, attached to an array of 6x8 Hamamatsu R1534 Photomultiplier tubes (PMTs). Compared to Anger logic, the ANNs showed an improvement in the spatial resolution as well as a decrease of the edge packing effect. The experimental setups were designed and validated with GATE software. {\textcopyright} 2011 IEEE.},
author = {Venialgo, E. and Verrastro, C. and Estryk, D. and Belzunce, M. and Carimatto, A. and {Da Ponte}, E. and {Martinez Garbino}, L. and Alarc{\'{o}}n, J.},
booktitle = {IEEE Nucl. Sci. Symp. Conf. Rec.},
doi = {10.1109/NSSMIC.2011.6152609},
isbn = {9781467301183},
issn = {10957863},
pages = {3359--3364},
title = {{PET calibration method of nonlinear position estimation algorithms for continuous NaI(Tl) crystals}},
year = {2011}
}
@inproceedings{Venialgo2012,
abstract = {In recent years, nuclear waste management has become a fundamental issue in the nuclear energy production cycle. Tomographic Gamma Scanner (TGS) is an essential tool for nuclear waste characterization. It is crucial to rely on local support and cost effective solutions; for this reasons, we are designing our TGS system based on local technology. In this work, we present a study of different geometries and instrumentation chain parameters to design a TGS. A set of Monte Carlo simulations were performed to evaluate energy and spatial resolution limitations of scintillator, CZT (Cadmium Zinc Telluride), and HPGe (high purity germanium) detectors. Collimator and detector geometries were studied to maximize the characteristics of the system. In this study, a phantom of 137Cs and 60Co was utilized to evaluate the overall performance of the proposed TGS system. In addition, the impact of electronic instrumentation chain and image reconstruction algorithms was taken into account. {\textcopyright} 2012 Materials Research Society.},
author = {Venialgo, Esteban and Belzunce, Martin and Verrastro, Claudio and Garbino, Lucio Mart{\'{i}}nez and {Da Ponte}, Elias and Alarc{\'{o}}n, Juan and Carimatto, Augusto and Estryk, Daniel and Prieto, Isabel},
booktitle = {Mater. Res. Soc. Symp. Proc.},
doi = {10.1557/opl.2012.628},
isbn = {9781605114521},
issn = {02729172},
pages = {533--538},
title = {{Analysis and comparison of Tomographic Gamma Scanner (TGS) architectures for nuclear waste characterization systems}},
volume = {1475},
year = {2012}
}
@inproceedings{Estryk2010,
abstract = {In this work, the AR-PET architecture is introduced and described. Its data acquisition system is composed of four layers of data processing with the purpose of computing the parameters as soon as possible to reduce data bandwidth for the next layer. FPGAs were used as main processing devices for the first three layers. The first layer computes pulse energy and timestamp, the second layer computes planar coordinates and the third layer does electronic collimation and spatial line of response computation. Some important issues, like time synchronization, data flow, trigger technique, configuration and programming buses are explained. The developed architecture was proved to be effective for PET scanner implementations. {\textcopyright} 2010 IEEE.},
author = {Estryk, D. S. and Verrastro, C. A. and Marinsek, S. and Belzunce, M. A. and Venialgo, E.},
booktitle = {6th South. Program. Log. Conf. SPL 2010 - Proc.},
doi = {10.1109/SPL.2010.5483028},
isbn = {9781424470891},
pages = {113--118},
title = {{FPGA hierarchical architecture for a positron emission tomography scanner}},
year = {2010}
}
@inproceedings{Garbino2016,
abstract = {The simulator presented in this work allowed to generate pulses of an arbitrary number of photons, that were used to evaluate the performance of the entire measurement chain of the AR-PET. The simulated pulses were validated by performing comparisons with real pulses acquired with an oscilloscope Tektronix DPO4104 model (Fs = 5 GHz, BW = 1GHz, 8 bits). In Figure 2, a simulated pulse superimposed on a measured sample pulse is shown.},
author = {Garbino, L. J.Martinez and Venialgo, E. and Estryk, D. and Verrastro, C. and Belzunce, M.},
booktitle = {2014 IEEE Nucl. Sci. Symp. Med. Imaging Conf. NSS/MIC 2014},
doi = {10.1109/NSSMIC.2014.7430981},
isbn = {9781479960972},
title = {{A pulse modeling tool for PET scanners}},
year = {2016}
}
@inproceedings{MABelzunceCVerrastro2009,
abstract = {Using iterative algorithms for image reconstruction in 3D Positron Emission Tomography has shown to produce images with better quality than analytical methods. How ever, these algorithms are computationally expensive. New Graphic Processor Units (GPU) provides high performance at low cost and also programming tools that make possible to execute parallel algorithms easily in scientific applications. In this work, we try to achieve an acceleration of image reconstruction algorithms in 3D PET by using a GPU. A parallel implementation of the algorithm ML-EM 3D was developed using Siddon algorithm as Projector and Backprojector. Results show that accelerations of more than one order of magnitude can be achieved, keeping similar image quality. Resumen La utilizaci{\'{o}}n de algoritmos iterativos de reconstrucci{\'{o}}n de imagen en Tomograf{\'{i}}a por Emisi{\'{o}}n de Positrones 3D ha demostrado generar im{\'{a}}genes con mejor calidad de imagen, sin embargo estos algoritmos son computacionalmente costosos. La aparici{\'{o}}n de Procesadores Gr{\'{a}}ficos de muy alta performance a bajo costo, acompa{\~{n}}ados de entornos de programaci{\'{o}}n que facilitan la ejecuci{\'{o}}n de algoritmos en paralelo, ha facilitado la incorporaci{\'{o}}n de los mismos a aplicaciones cient{\'{i}}ficas. En este trabajo, se busca lograr la aceleraci{\'{o}}n de los tiempos de reconstrucci{\'{o}}n en PET 3D mediante la utilizaci{\'{o}}n de procesadores graficos. Se implement{\'{o}} el algoritmo ML-EM 3D, utlizando el algoritmo de Siddon como Proyector y Retroproyector. Los resultados demuestran que se pueden lograr aceleraciones de m{\'{a}}s de un orden de magnitud manteniendo las cualidades de la imagen. Palabras Clave: PET, Reconstrucci{\'{o}}n de Imagen, Procesadores Gr{\'{a}}ficos, ML-EM I. INTRODUCCI{\'{O}}N Y OBJETIVOS Los m{\'{e}}todos iterativos de reconstrucci{\'{o}}n tomogr{\'{a}}fica en PET (Positron Emission Tomography), basados en Maximum-Likelihood, han demostrado tener mejores resultados en lo que hace a resoluci{\'{o}}n y calidad de la imagen. Sin embargo, estos algoritmos tienen como desventaja que son computacionalmente costosos, especialmente en el caso de adquisici{\'{o}}n 3D, donde el volumen de datos manejados ha aumentado m{\'{a}}s de un orden de magnitud respecto de los primeros equipos PET. Esto hace que la carga de procesamiento y los requerimientos de memoria sean cada d{\'{i}}a mayores. El procesamiento tambi{\'{e}}n ha crecido debido a la incorporaci{\'{o}}n de modelos cada vez m{\'{a}}s complejos para mejorar la calidad de imagen. En los equipos actuales se requieren un conjunto de CPUs en paralelo (entre 8 y 12) para realizar la reconstrucci{\'{o}}n en tiempos aceptables. La aparici{\'{o}}n de procesadores gr{\'{a}}ficas (GPU) de alta performance, con m{\'{u}}ltiples unidades de procesamiento (hasta 280), y un entorno de programaci{\'{o}}n dise{\~{n}}ado para facilitar la implementaci{\'{o}}n de algoritmos en paralelo, ha puesto a disposici{\'{o}}n de la comunidad cient{\'{i}}fica una herramienta de alta potencialidad y costo relativamente bajo para acelerar los tiempos de ejecuci{\'{o}}n de algoritmos paralelizables. El objetivo del presente trabajo es reducir los tiempos de c{\'{a}}lculo en los algoritmos iterativos de reconstrucci{\'{o}}n mediante la implementaci{\'{o}}n de los mismos en procesadores gr{\'{a}}ficos. El},
author = {Belzunce, Martin A. and Verrastro, Claudio A. and Osorio, Amilcar},
booktitle = {XXXVI Reun. Anu. AATN},
file = {:C$\backslash$:/Users/martin/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/A, A - Unknown - ACELERACI{\'{O}}N DE M{\'{E}}TODO ITERATVIO DE RECONSTRUCCI{\'{O}}N TOMOGR{\'{A}}FICA MEDIANTE PROCESADORES GR{\'{A}}FICOS.pdf:pdf},
keywords = {graphics processor units,image reconstruction,ml-em,pet},
number = {hasta 280},
title = {{Aceleraci{\'{o}}n de m{\'{e}}todo iteratvio de reconstrucci{\'{o}}n tomogr{\'{a}}fica mediante procesadores gr{\'{a}}ficos}},
year = {2009}
}
@inproceedings{Belzunce2012a,
abstract = {Tomographic Gamma Scanners are novels tools for nondestructive assay and characterization of nuclear waste drums. In these scanners, a three dimensional image of the activity distribution of every radioisotope stored in the drum is obtained performing a single-photon emission tomography. AR-TGS is a novel architecture of tomographic gamma scanners that combines an HPGe detector with six NaI(Tl) detectors in order to achieve high-sensitivity. In this work, a projector for a 2D MLEM reconstruction algorithm of AR-TGS is presented. This projector models the geometry of the system, the collimator's response and the attenuation in the field of view performing a ray-tracing with several lines of response per detector. The projector was evaluated with Monte Carlo simulations and an experimental measurement. The algorithm proved to be an accurate model of the acquisition process and was used to reconstruct data sets with different strategies. The results showed that the image reconstruction with this method improved considerably spatial resolution and image quality compared with an attenuated Siddon projector. {\textcopyright} 2012 IEEE.},
author = {Belzunce, Martin and Verrastro, Claudio and Venialgo, Esteban and {Da Ponte}, Elias and Carimatto, Augusto and Garbino, Lucio Martinez and Alarcon, Juan and Estryk, Daniel},
booktitle = {IEEE Nucl. Sci. Symp. Conf. Rec.},
doi = {10.1109/NSSMIC.2012.6551248},
isbn = {9781467320306},
issn = {10957863},
pages = {951--957},
title = {{An attenuated projector for iterative reconstruction algorithm of a novel Tomographic Gamma Scanner}},
year = {2012}
}
@inproceedings{Belzunce2017b,
author = {Belzunce, Martin A. and Mehranian, Abolfazl and Chalampalakis, Zacharias and Reader, Andrew Jonathan},
booktitle = {PSMR Conf.},
title = {{Evaluation of shift-invariant image-space PSFs for the Biograph mMR PET Scanner}},
year = {2017}
}
@inproceedings{Balfour2018,
abstract = {In simultaneous PET-MR scanning, respiratory motion can lead to artefacts and blurring in both PET and MR images, negatively impacting research and clinical applications. This can be compensated for by estimating respiratory motion through a respiratory signal. Here, we propose a data-driven dimensionality-reduction-based technique which aligns manifolds formed from both PET and MR data to produce a robust signal even in situations where MR data are unavailable, as expected in realistic workflows. To handle the missing MR data, 3 methods for semi-supervised manifold alignment alignment were tested using a semi-synthetic dataset consisting of 500 0.64 s dynamic MR volumes and PET sinograms. It was found that implicit correspondences for unlabelled PET data were most effective on average for signal estimation, at 81 ± 4{\%} mean correlation to a gold standard diaphragmatic navigator, compared to 89 ± 0.2{\%} when using MR only with no missing data. Two explicit correspondence estimators, based on graph theory, performed poorly, with 1-to-1 and many-to-1 correspondences achieving 34 ±16{\%} correlation and 31 ± 9{\%} correlation, respectively.},
author = {Balfour, D. R. and Clough, J. R. and Chen, X. and Belzunce, M. and Prieto, C. and Marsden, P. K. and Reader, A. J. and King, A. P.},
booktitle = {Proc. - Int. Symp. Biomed. Imaging},
doi = {10.1109/ISBI.2018.8363647},
isbn = {9781538636367},
issn = {19458452},
keywords = {Laplacian eigenmaps,Machine learning,Manifold alignment,Respiratory motion,Simultaneous PET-MR},
pages = {599--603},
title = {{PET-MR respiratory signal estimation using semi-supervised manifold alignment}},
volume = {2018-April},
year = {2018}
}
